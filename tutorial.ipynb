{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This module estimates parameters of probability distributions with MLE for independent and identically distributed data\n",
    "### Jacobian and Hessian of the log likelihood functions are calculated symbolically for higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import mle\n",
    "import pdfs\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Data from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "\n",
    "mu_true, s_true = 2.5, 1.3\n",
    "\n",
    "data_norm = np.random.normal(loc=mu_true, scale=s_true, size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate distribution parameters with symbolic MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 25.200511022960903\n",
      " hess_inv: array([[0.08622745, 0.00065178],\n",
      "       [0.00065178, 0.04320367]])\n",
      "      jac: array([-1.31988812e-07, -2.04829813e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 10\n",
      "     njev: 12\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([2.05723033, 1.16893537])\n",
      "==================================================\n",
      "mu = 2.0572 +/- 0.2922 \n",
      "s = 1.1689 +/- 0.2066 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37/lib/python3.7/site-packages/scipy/optimize/_minimize.py:507: RuntimeWarning: Method bfgs does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "norm = pdfs.normal()\n",
    "model_norm = mle.mle_model_iids(data_norm, mle.make_MLE_model(norm))\n",
    "\n",
    "fit_res_norm = mle.fit_mle(model_norm, [1., 1.]) \n",
    "print(fit_res_norm)\n",
    "covar_norm = mle.mle_param_covar(fit_res_norm.x, model_norm)\n",
    "\n",
    "print(50*'=')\n",
    "for name, val, err in zip(model_norm.pars, fit_res_norm.x, np.sqrt(np.diag(covar_norm))):\n",
    "    print(f'{name} = {val:.4f} +/- {err:.4f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate with StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.575032\n",
      "         Iterations: 42\n",
      "         Function evaluations: 79\n",
      "                                 Norm Results                                 \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -25.201\n",
      "Model:                           Norm   AIC:                             56.40\n",
      "Method:            Maximum Likelihood   BIC:                             58.72\n",
      "Date:                Wed, 10 Apr 2019                                         \n",
      "Time:                        14:40:35                                         \n",
      "No. Observations:                  16                                         \n",
      "Df Residuals:                      14                                         \n",
      "Df Model:                           2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "par0           2.0572      0.292      7.039      0.000       1.484       2.630\n",
      "par1           1.1690      0.207      5.657      0.000       0.764       1.574\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class Norm(GenericLikelihoodModel):\n",
    "\n",
    "    nparams = 3\n",
    "\n",
    "    def loglike(self, params):\n",
    "        return ss.norm.logpdf(self.endog, *params).sum()\n",
    "    \n",
    "res = Norm(data_norm).fit(start_params=[1., 1.])\n",
    "res.df_model = 2\n",
    "res.df_resid = len(data_norm) - 2\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Data from an exponential distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "\n",
    "mu_true = 1.5\n",
    "\n",
    "data_expon = np.random.exponential(scale=mu_true, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 23.47071732285937\n",
      " hess_inv: array([[0.1596467]])\n",
      "      jac: array([3.30082115e-06])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 8\n",
      "      nit: 7\n",
      "     njev: 8\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([1.59507405])\n",
      "==================================================\n",
      "mu = 1.5951 +/- 0.3988 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37/lib/python3.7/site-packages/scipy/optimize/_minimize.py:507: RuntimeWarning: Method bfgs does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "expon = pdfs.expon()\n",
    "model_expon = mle.mle_model_iids(data_expon, mle.make_MLE_model(expon))\n",
    "\n",
    "fit_res_expon = mle.fit_mle(model_expon, [1.]) \n",
    "print(fit_res_expon)\n",
    "covar_expon = mle.mle_param_covar(fit_res_expon.x, model_expon)\n",
    "\n",
    "print(50*'=')\n",
    "for name, val, err in zip(model_expon.pars, fit_res_expon.x, np.sqrt(np.diag(covar_expon))):\n",
    "    print(f'{name} = {val:.4f} +/- {err:.4f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate with StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "                                Expon Results                                 \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                   -inf\n",
      "Model:                          Expon   AIC:                               inf\n",
      "Method:            Maximum Likelihood   BIC:                               inf\n",
      "Date:                Wed, 10 Apr 2019                                         \n",
      "Time:                        14:45:24                                         \n",
      "No. Observations:                  16                                         \n",
      "Df Residuals:                      15                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "par0           1.0000        nan        nan        nan         nan         nan\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37/lib/python3.7/site-packages/scipy/optimize/optimize.py:563: RuntimeWarning: invalid value encountered in subtract\n",
      "  numpy.max(numpy.abs(fsim[0] - fsim[1:])) <= fatol):\n",
      "/anaconda/envs/py37/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:351: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  - (f(*((x - ee[i, :] + ee[j, :],) + args), **kwargs)\n",
      "/anaconda/envs/py37/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:352: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  - f(*((x - ee[i, :] - ee[j, :],) + args), **kwargs))\n",
      "/anaconda/envs/py37/lib/python3.7/site-packages/statsmodels/base/model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/anaconda/envs/py37/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "class Expon(GenericLikelihoodModel):\n",
    "\n",
    "    nparams = 3\n",
    "\n",
    "    def loglike(self, params):\n",
    "        return ss.expon.logpdf(self.endog, *params).sum()\n",
    "    \n",
    "res = Expon(data_expon).fit(start_params=[1.])\n",
    "res.df_model = 1\n",
    "res.df_resid = len(data_expon) - 1\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Mixture of two normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "p, mu1, s1, mu2, s2 = 0.7, 1., 0.4, 2., 0.3\n",
    "\n",
    "a = np.random.binomial(1, p, size=N)\n",
    "\n",
    "data_sum_norm = a*np.random.normal(loc=mu1, scale=s1, size=N) + \\\n",
    "(1-a)*np.random.normal(loc=mu2, scale=s2, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bins, _ = hist(data_sum_norm, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37/lib/python3.7/site-packages/scipy/optimize/_minimize.py:502: RuntimeWarning: Method nelder-mead does not use gradient information (jac).\n",
      "  RuntimeWarning)\n",
      "/anaconda/envs/py37/lib/python3.7/site-packages/scipy/optimize/_minimize.py:507: RuntimeWarning: Method nelder-mead does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[0.73609134, 1.00253217, 0.40902397, 2.07407513, 0.28101308],\n",
      "       [0.73613816, 1.00255368, 0.40902859, 2.07412451, 0.2809671 ],\n",
      "       [0.73613184, 1.00259026, 0.40905274, 2.07415348, 0.28097311],\n",
      "       [0.73612935, 1.00257623, 0.40906427, 2.07411384, 0.28098599],\n",
      "       [0.73608862, 1.00254107, 0.40903456, 2.07414007, 0.28096971],\n",
      "       [0.73611511, 1.00253013, 0.40903695, 2.07414057, 0.28100761]]), array([863.27949639, 863.2794967 , 863.27949713, 863.2794972 ,\n",
      "       863.27949883, 863.27949899]))\n",
      "           fun: 863.2794963869468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 280\n",
      "           nit: 173\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.73609134, 1.00253217, 0.40902397, 2.07407513, 0.28101308])\n",
      "==================================================\n",
      "p = 0.7361 +/- 0.0262 \n",
      "mu1 = 1.0025 +/- 0.0263 \n",
      "s1 = 0.4090 +/- 0.0186 \n",
      "mu2 = 2.0741 +/- 0.0359 \n",
      "s2 = 0.2810 +/- 0.0225 \n"
     ]
    }
   ],
   "source": [
    "sum_norm = pdfs.sum_two_normal()\n",
    "model_sum_norm = mle.mle_model_iids(data_sum_norm, mle.make_MLE_model(sum_norm))\n",
    "\n",
    "fit_res_sum_norm = mle.fit_mle(model_sum_norm, [0.6, 1.1, 0.5, 2.1, 0.4], method='nelder-mead') \n",
    "print(fit_res_sum_norm)\n",
    "covar_sum_norm = mle.mle_param_covar(fit_res_sum_norm.x, model_sum_norm)\n",
    "\n",
    "print(50*'=')\n",
    "for name, val, err in zip(model_sum_norm.pars, fit_res_sum_norm.x, np.sqrt(np.diag(covar_sum_norm))):\n",
    "    print(f'{name} = {val:.4f} +/- {err:.4f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers = 0.5*(bins[1:] + bins[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[0.73314413, 1.00269759, 0.41639695, 2.07019994, 0.30231073],\n",
      "       [0.733198  , 1.00274196, 0.41642735, 2.07026929, 0.30229732],\n",
      "       [0.73320134, 1.00275648, 0.41643217, 2.07029751, 0.30226518],\n",
      "       [0.73315264, 1.00268692, 0.41640926, 2.07020052, 0.30232921],\n",
      "       [0.73320295, 1.00272558, 0.41642289, 2.07025621, 0.30227152],\n",
      "       [0.73317188, 1.00272154, 0.4164376 , 2.07020688, 0.30231883]]), array([880.69750818, 880.6975083 , 880.69750841, 880.69750875,\n",
      "       880.69750943, 880.69751052]))\n",
      "           fun: 880.6975081755268\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 277\n",
      "           nit: 166\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.73314413, 1.00269759, 0.41639695, 2.07019994, 0.30231073])\n",
      "==================================================\n",
      "p = 0.7331 +/- 0.0311 \n",
      "mu1 = 1.0027 +/- 0.0304 \n",
      "s1 = 0.4164 +/- 0.0206 \n",
      "mu2 = 2.0702 +/- 0.0447 \n",
      "s2 = 0.3023 +/- 0.0265 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37/lib/python3.7/site-packages/scipy/optimize/_minimize.py:502: RuntimeWarning: Method nelder-mead does not use gradient information (jac).\n",
      "  RuntimeWarning)\n",
      "/anaconda/envs/py37/lib/python3.7/site-packages/scipy/optimize/_minimize.py:507: RuntimeWarning: Method nelder-mead does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "sum_norm = pdfs.sum_two_normal()\n",
    "model_sum_norm = mle.mle_model_iids_hist(bin_centers, counts, mle.make_MLE_model(sum_norm))\n",
    "\n",
    "fit_res_sum_norm = mle.fit_mle(model_sum_norm, [0.6, 1.1, 0.5, 2.1, 0.4], method='nelder-mead') \n",
    "print(fit_res_sum_norm)\n",
    "covar_sum_norm = mle.mle_param_covar(fit_res_sum_norm.x, model_sum_norm)\n",
    "\n",
    "print(50*'=')\n",
    "for name, val, err in zip(model_sum_norm.pars, fit_res_sum_norm.x, np.sqrt(np.diag(covar_sum_norm))):\n",
    "    print(f'{name} = {val:.4f} +/- {err:.4f} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
